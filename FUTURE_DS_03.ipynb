{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qJN4b9ilpJnr",
        "outputId": "707526ac-85e0-45d6-dc31-eb3f982e0f9e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3b1c1b4e-6452-4530-8ebb-89eb3f2bc16e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3b1c1b4e-6452-4530-8ebb-89eb3f2bc16e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving loan.csv to loan (8).csv\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 614 entries, 0 to 613\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Loan_ID            614 non-null    object \n",
            " 1   Gender             601 non-null    object \n",
            " 2   Married            611 non-null    object \n",
            " 3   Dependents         599 non-null    object \n",
            " 4   Education          614 non-null    object \n",
            " 5   Self_Employed      582 non-null    object \n",
            " 6   ApplicantIncome    614 non-null    int64  \n",
            " 7   CoapplicantIncome  614 non-null    float64\n",
            " 8   LoanAmount         592 non-null    float64\n",
            " 9   Loan_Amount_Term   600 non-null    float64\n",
            " 10  Credit_History     564 non-null    float64\n",
            " 11  Property_Area      614 non-null    object \n",
            " 12  Loan_Status        614 non-null    object \n",
            "dtypes: float64(4), int64(1), object(8)\n",
            "memory usage: 62.5+ KB\n",
            "Gender               0\n",
            "Married              0\n",
            "Dependents           0\n",
            "Education            0\n",
            "Self_Employed        0\n",
            "ApplicantIncome      0\n",
            "CoapplicantIncome    0\n",
            "LoanAmount           0\n",
            "Loan_Amount_Term     0\n",
            "Credit_History       0\n",
            "Property_Area        0\n",
            "Loan_Status          0\n",
            "dtype: int64\n",
            "\n",
            "Descriptive statistics of the cleaned dataset:\n",
            "           Gender     Married  Dependents   Education  Self_Employed  \\\n",
            "count  614.000000  614.000000  614.000000  614.000000     614.000000   \n",
            "mean     0.817590    0.653094    0.744300    0.218241       0.133550   \n",
            "std      0.386497    0.476373    1.009623    0.413389       0.340446   \n",
            "min      0.000000    0.000000    0.000000    0.000000       0.000000   \n",
            "25%      1.000000    0.000000    0.000000    0.000000       0.000000   \n",
            "50%      1.000000    1.000000    0.000000    0.000000       0.000000   \n",
            "75%      1.000000    1.000000    1.000000    0.000000       0.000000   \n",
            "max      1.000000    1.000000    3.000000    1.000000       1.000000   \n",
            "\n",
            "       ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
            "count       614.000000         614.000000  614.000000        614.000000   \n",
            "mean       5403.459283        1621.245798  145.752443        342.410423   \n",
            "std        6109.041673        2926.248369   84.107233         64.428629   \n",
            "min         150.000000           0.000000    9.000000         12.000000   \n",
            "25%        2877.500000           0.000000  100.250000        360.000000   \n",
            "50%        3812.500000        1188.500000  128.000000        360.000000   \n",
            "75%        5795.000000        2297.250000  164.750000        360.000000   \n",
            "max       81000.000000       41667.000000  700.000000        480.000000   \n",
            "\n",
            "       Credit_History  Property_Area  Loan_Status  \n",
            "count      614.000000     614.000000   614.000000  \n",
            "mean         0.855049       1.037459     0.687296  \n",
            "std          0.352339       0.787482     0.463973  \n",
            "min          0.000000       0.000000     0.000000  \n",
            "25%          1.000000       0.000000     0.000000  \n",
            "50%          1.000000       1.000000     1.000000  \n",
            "75%          1.000000       2.000000     1.000000  \n",
            "max          1.000000       2.000000     1.000000  \n",
            "\n",
            "Correlation matrix:\n",
            "                     Gender   Married  Dependents  Education  Self_Employed  \\\n",
            "Gender             1.000000  0.364569    0.172914   0.045364      -0.000525   \n",
            "Married            0.364569  1.000000    0.334216   0.012304       0.004489   \n",
            "Dependents         0.172914  0.334216    1.000000   0.055752       0.056798   \n",
            "Education          0.045364  0.012304    0.055752   1.000000      -0.010383   \n",
            "Self_Employed     -0.000525  0.004489    0.056798  -0.010383       1.000000   \n",
            "ApplicantIncome    0.058809  0.051708    0.118202  -0.140760       0.127180   \n",
            "CoapplicantIncome  0.082912  0.075948    0.030430  -0.062290      -0.016100   \n",
            "LoanAmount         0.106904  0.146546    0.163103  -0.168759       0.115100   \n",
            "Loan_Amount_Term  -0.074030 -0.100912   -0.103864  -0.073928      -0.033739   \n",
            "Credit_History     0.009170  0.010938   -0.040160  -0.073658      -0.001550   \n",
            "Property_Area     -0.025752  0.004257   -0.000244  -0.065243      -0.030860   \n",
            "Loan_Status        0.017987  0.091478    0.010118  -0.085884      -0.003700   \n",
            "\n",
            "                   ApplicantIncome  CoapplicantIncome  LoanAmount  \\\n",
            "Gender                    0.058809           0.082912    0.106904   \n",
            "Married                   0.051708           0.075948    0.146546   \n",
            "Dependents                0.118202           0.030430    0.163103   \n",
            "Education                -0.140760          -0.062290   -0.168759   \n",
            "Self_Employed             0.127180          -0.016100    0.115100   \n",
            "ApplicantIncome           1.000000          -0.116605    0.565181   \n",
            "CoapplicantIncome        -0.116605           1.000000    0.189218   \n",
            "LoanAmount                0.565181           0.189218    1.000000   \n",
            "Loan_Amount_Term         -0.046531          -0.059383    0.036960   \n",
            "Credit_History           -0.018615           0.011134   -0.000607   \n",
            "Property_Area            -0.009500           0.010522   -0.046632   \n",
            "Loan_Status              -0.004710          -0.059187   -0.033214   \n",
            "\n",
            "                   Loan_Amount_Term  Credit_History  Property_Area  \\\n",
            "Gender                    -0.074030        0.009170      -0.025752   \n",
            "Married                   -0.100912        0.010938       0.004257   \n",
            "Dependents                -0.103864       -0.040160      -0.000244   \n",
            "Education                 -0.073928       -0.073658      -0.065243   \n",
            "Self_Employed             -0.033739       -0.001550      -0.030860   \n",
            "ApplicantIncome           -0.046531       -0.018615      -0.009500   \n",
            "CoapplicantIncome         -0.059383        0.011134       0.010522   \n",
            "LoanAmount                 0.036960       -0.000607      -0.046632   \n",
            "Loan_Amount_Term           1.000000       -0.004705      -0.076120   \n",
            "Credit_History            -0.004705        1.000000       0.001963   \n",
            "Property_Area             -0.076120        0.001963       1.000000   \n",
            "Loan_Status               -0.022549        0.540556       0.032112   \n",
            "\n",
            "                   Loan_Status  \n",
            "Gender                0.017987  \n",
            "Married               0.091478  \n",
            "Dependents            0.010118  \n",
            "Education            -0.085884  \n",
            "Self_Employed        -0.003700  \n",
            "ApplicantIncome      -0.004710  \n",
            "CoapplicantIncome    -0.059187  \n",
            "LoanAmount           -0.033214  \n",
            "Loan_Amount_Term     -0.022549  \n",
            "Credit_History        0.540556  \n",
            "Property_Area         0.032112  \n",
            "Loan_Status           1.000000  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f2e8f2855573>:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)        # Fill missing values for categorical columns with mode\n",
            "<ipython-input-9-f2e8f2855573>:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Married'].fillna(df['Married'].mode()[0], inplace=True)\n",
            "<ipython-input-9-f2e8f2855573>:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)\n",
            "<ipython-input-9-f2e8f2855573>:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)\n",
            "<ipython-input-9-f2e8f2855573>:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True) # Fill missing values for numerical columns with median\n",
            "<ipython-input-9-f2e8f2855573>:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)\n",
            "<ipython-input-9-f2e8f2855573>:39: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Credit_History'].fillna(df['Credit_History'].median(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.75\n",
            "Confusion Matrix:\n",
            "[[18 25]\n",
            " [ 6 74]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.42      0.54        43\n",
            "           1       0.75      0.93      0.83        80\n",
            "\n",
            "    accuracy                           0.75       123\n",
            "   macro avg       0.75      0.67      0.68       123\n",
            "weighted avg       0.75      0.75      0.73       123\n",
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.79\n",
            "Confusion Matrix:\n",
            "[[18 25]\n",
            " [ 1 79]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.42      0.58        43\n",
            "           1       0.76      0.99      0.86        80\n",
            "\n",
            "    accuracy                           0.79       123\n",
            "   macro avg       0.85      0.70      0.72       123\n",
            "weighted avg       0.83      0.79      0.76       123\n",
            "\n",
            "\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.79\n",
            "Confusion Matrix:\n",
            "[[18 25]\n",
            " [ 1 79]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.42      0.58        43\n",
            "           1       0.76      0.99      0.86        80\n",
            "\n",
            "    accuracy                           0.79       123\n",
            "   macro avg       0.85      0.70      0.72       123\n",
            "weighted avg       0.83      0.79      0.76       123\n",
            "\n",
            "\n",
            "Decision Tree Classifier Results:\n",
            "Accuracy: 0.69\n",
            "Confusion Matrix:\n",
            "[[23 20]\n",
            " [18 62]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.53      0.55        43\n",
            "           1       0.76      0.78      0.77        80\n",
            "\n",
            "    accuracy                           0.69       123\n",
            "   macro avg       0.66      0.65      0.66       123\n",
            "weighted avg       0.69      0.69      0.69       123\n",
            "\n",
            "\n",
            "K-Nearest Neighbors Results:\n",
            "Accuracy: 0.76\n",
            "Confusion Matrix:\n",
            "[[17 26]\n",
            " [ 4 76]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.40      0.53        43\n",
            "           1       0.75      0.95      0.84        80\n",
            "\n",
            "    accuracy                           0.76       123\n",
            "   macro avg       0.78      0.67      0.68       123\n",
            "weighted avg       0.77      0.76      0.73       123\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression:\n",
            "Cross-Validation Scores (k=5): [0.81300813 0.77235772 0.7804878  0.85365854 0.81147541]\n",
            "Mean Accuracy: 0.81\n",
            "Standard Deviation: 0.03\n",
            "\n",
            "Support Vector Machine (SVM):\n",
            "Cross-Validation Scores (k=5): [0.69105691 0.69105691 0.68292683 0.68292683 0.68852459]\n",
            "Mean Accuracy: 0.69\n",
            "Standard Deviation: 0.00\n",
            "\n",
            "Decision Tree Classifier:\n",
            "Cross-Validation Scores (k=5): [0.75609756 0.63414634 0.70731707 0.73170732 0.72131148]\n",
            "Mean Accuracy: 0.71\n",
            "Standard Deviation: 0.04\n",
            "\n",
            "K-Nearest Neighbors (KNN):\n",
            "Cross-Validation Scores (k=5): [0.63414634 0.6097561  0.62601626 0.58536585 0.6147541 ]\n",
            "Mean Accuracy: 0.61\n",
            "Standard Deviation: 0.02\n",
            "\n",
            "Random Forest Classifier:\n",
            "Cross-Validation Scores (k=5): [0.78861789 0.73170732 0.7804878  0.82113821 0.80327869]\n",
            "Mean Accuracy: 0.79\n",
            "Standard Deviation: 0.03\n"
          ]
        }
      ],
      "source": [
        "# Basic libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv('loan.csv')\n",
        "\n",
        "\n",
        "#Exploring the Dataset\n",
        "df.head()                         # Check the first few rows\n",
        "df.info()                         # Dataset information\n",
        "df.describe()                     # Statistical summary\n",
        "df.isnull().sum()                 # Check for missing values\n",
        "\n",
        "\n",
        "#Data Cleaning and Preprocessing\n",
        "df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)        # Fill missing values for categorical columns with mode\n",
        "df['Married'].fillna(df['Married'].mode()[0], inplace=True)\n",
        "df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)\n",
        "df['Self_Employed'].fillna(df['Self_Employed'].mode()[0], inplace=True)\n",
        "df['LoanAmount'].fillna(df['LoanAmount'].median(), inplace=True) # Fill missing values for numerical columns with median\n",
        "df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].median(), inplace=True)\n",
        "df['Credit_History'].fillna(df['Credit_History'].median(), inplace=True)\n",
        "label_enc = LabelEncoder()                                       # Encode categorical variables using LabelEncoder\n",
        "df['Gender'] = label_enc.fit_transform(df['Gender'])\n",
        "df['Married'] = label_enc.fit_transform(df['Married'])\n",
        "df['Education'] = label_enc.fit_transform(df['Education'])\n",
        "df['Self_Employed'] = label_enc.fit_transform(df['Self_Employed'])\n",
        "df['Property_Area'] = label_enc.fit_transform(df['Property_Area'])\n",
        "df['Loan_Status'] = label_enc.fit_transform(df['Loan_Status'])\n",
        "df['Dependents'] = df['Dependents'].replace('3+', 3).astype(int)  # Encode 'Dependents' (handle the '3+' case)\n",
        "df.drop('Loan_ID', axis=1, inplace=True)                          # Drop the Loan_ID column(Dropping Irrelevant column)\n",
        "print(df.isnull().sum())                                          # Check for any remaining missing values\n",
        "df.head()                                                         # View the first few rows of the cleaned dataset\n",
        "\n",
        "# Descriptive Statistics\n",
        "print(\"\\nDescriptive statistics of the cleaned dataset:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Correlation Matrix\n",
        "print(\"\\nCorrelation matrix:\")\n",
        "corr_matrix = df.corr()\n",
        "print(corr_matrix)\n",
        "\n",
        "\n",
        "\n",
        "# Features and target variable\n",
        "X = df.drop('Loan_Status', axis=1)                                # Drop the target column to get features\n",
        "y = df['Loan_Status']                                             # Target column\n",
        "\n",
        "\n",
        "# Split the dataset(80-20 split for training and testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "#Feature Scaling\n",
        "scaler = StandardScaler()                                          # Initialize the scaler\n",
        "X_train = scaler.fit_transform(X_train)                            # Scale the training and testing feature sets\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#Random Forest Classifier\n",
        "model = RandomForestClassifier(random_state=42)                    # Initialize the Random Forest Classifier\n",
        "model.fit(X_train, y_train)                                        # Train the model on the training data\n",
        "y_pred = model.predict(X_test)                                     # Make predictions on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)                          # Evaluate the model\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(max_iter=1000, random_state=42)      # Initialize and train the model\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred_log_reg = log_reg.predict(X_test)                          # Make predictions\n",
        "print(\"Logistic Regression Results:\")                             # Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg):.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_log_reg))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "\n",
        "#Support vector machine (SVM)\n",
        "from sklearn.svm import SVC\n",
        "svm_model = SVC(kernel='linear', random_state=42)                # Initialize and train the model\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)                           # Make predictions\n",
        "print(\"\\nSupport Vector Machine Results:\")                       # Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm):.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)              # Initialize and train the model\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)                            # Make predictions\n",
        "print(\"\\nDecision Tree Classifier Results:\")                    # Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt):.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "\n",
        "\n",
        "#K-Nearest Neighbors (KNN)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)                 # Initialize and train the model\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test)                          # Make predictions\n",
        "print(\"\\nK-Nearest Neighbors Results:\")                         # Evaluate the model\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.2f}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "\n",
        "#Cross validation\n",
        "# List of models to evaluate\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Support Vector Machine (SVM)': SVC(),\n",
        "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=42),\n",
        "    'K-Nearest Neighbors (KNN)': KNeighborsClassifier(),\n",
        "    'Random Forest Classifier': RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Perform k-fold cross-validation for each model\n",
        "k = 5\n",
        "for model_name, model in models.items():\n",
        "    # Perform cross-validation\n",
        "    cv_scores = cross_val_score(model, X, y, cv=k, scoring='accuracy')\n",
        "\n",
        "    # Print the cross-validation results for the model\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"Cross-Validation Scores (k={k}): {cv_scores}\")\n",
        "    print(f\"Mean Accuracy: {np.mean(cv_scores):.2f}\")\n",
        "    print(f\"Standard Deviation: {np.std(cv_scores):.2f}\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}